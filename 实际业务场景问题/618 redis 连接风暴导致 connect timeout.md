# 问题背景
抢券活动后台使用了 Redis，抢券开始时，用户抢到券，但实际券未到账。经日志排查发现后端连接 redis 报 connect timeout，而前端认为成功了。

# 问题分析与排查

**定位客户端问题还是服务端问题**
从错误日志分布来看，所有机器都短暂的出现大量的 connect timeout 异常，则初步认为与客户端无关，是服务器的问题。通过查看 redis 服务器的监控，redis 机器 cpu 不高，但 cps 每秒基本都处于 1000+左右（cps 表示每秒创建的连接数），每秒创建1000多条连接，因此假定问题是由于连接风暴导致的

**定位为什么会产生连接风暴**
查看客户端应用的连接池配置，发现 jedis 连接池中两个参数
- connectTimeout：1000，连接超时时间
- maxIdle: 10  最大空闲连接数
- maxTotal: 20 最大连接数

Jedis 客户端的连接管理机制：
- 获取连接时，如果当前无可用连接且连接数少于 maxTotal，则创建新连接
- 归还连接时，如果当前 idle 连接< maxIdle，则将连接放进池中；如果 >= maxIdle直接销毁连接，则直接将连接销毁

因此这就解释了在抢券高并发场景中，大于 10 的连接基本都是短链接，用完直接 close 掉，所以导致了连接风暴的产生。
因此只需要将 maxIdle 和 maxTotal 配置成一致，则可以解决连接风暴的问题。

**连接风暴为什么会导致 connect timeout**
由于无法在线上定位，因此通过线下模拟，并用 jmeter 进行压测，发现当 cps 为200左右的时候，也会偶尔出现 connect timeout 异常。通过 tcpdump 和 wireshark 抓包分析发现出现丢包的情况，这个问题与 TCP 机制层面有关

以客户端和服务端(redis)通信过程来说明这个问题

请求 A 到来
1. 首先客户端与服务端建立了通信，假设客户端占用的端口号为 33333
2. 请求结束，客户端主动 close 连接
3. 服务端回了 fin/ack 后，并没有收到客户端的 ACK 报文，导致服务端一直处于 last_ack 状态，此时服务端认为连接还未关闭

请求 B 到来
1. 由于打开了 tcp_reuse，客户端不需要等待 time_wait 状态，直接复用了端口 33333 的连接，向服务端发送 syn 报文
2. 服务端收到 SYN 报文，但是由于服务端认为连接还未关闭，所以丢弃了 SYN 报文，重传了 FIN/ACK
3. 客户端收到 FIN/ACK 报文，因为该报文属于旧连接的，因此回了一个 RST 报文，继续等待之前发送 SYN 报文的确认
4. 服务端收到 RST 报文，主动关闭了连接
5. 客户端 1s 后还未收到 SYN/ACK 报文，则触发重传，但此时 connect timeout 为 1s，则同时也触发 connect timeout 异常

主要原因是由于：打开了 tcp_reuse，触发了端口复用，同时由于旧连接出现丢包情况，未正常关闭导致超时

**time_wait 的作用是什么**
在四次挥手中，客户端回了最后的 ACK 报文后，会处于 time_wait 状态，该状态持续 2msl 时间（msl = 报文最大的存活时间），主要作用是
1. 保证旧连接中仍在网络传输中的报文都被过期掉，避免新连接收到旧报文；
2. 重传最后的 ACK 报文，避免服务端没收到最后的 ACK 报文而导致连接未关闭

# 解决方案
1. 设置 maxIdle = maxTotal
2. 若对于超时不敏感的应用，connectTimeout 可设置略大于1s，保证能收到重传后的确认
